{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b322b507e82f0fad8b8cf925570d0183",
     "grade": false,
     "grade_id": "cell-26305605ed4b4084",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 3 \n",
    "\n",
    "In this assignment:\n",
    "\n",
    "Part 1 - Theoretical questions regarding bootstrap sampling and random forests.\n",
    "\n",
    "Part 2- We will implement and analyze a famous algorithm which utillizes **AdaBoost** both for feature selection and as a final model for image classification.\n",
    "\n",
    "## Environment Setup / Dependencies\n",
    "\n",
    "This assignment has some additional dependencies beyond what we have used so far:\n",
    "1. scikit-image, version 0.15.0\n",
    "2. cifar10_web\n",
    "3. joblib - used to parallelize for loops\n",
    "\n",
    "First check if you already have scikit-image installed by running the below import cells. Otherwise:\n",
    "`conda install scikit-image` or `pip install scikit-image`, and repeat for the other libraries.\n",
    "\n",
    "Check the scikit-image version in the import cell below. You should have 0.15.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6383cfbd56cdb5261f9edb9472246834",
     "grade": false,
     "grade_id": "cell-4cba02a2e616cb97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1 : Bootstrapping and Random Forest Questions (4 pts)\n",
    "\n",
    "For the first part, please answer the following questions **in the cell below**.\n",
    "\n",
    "In the practical part of this assignment, we will use **boosting**. However there are other algorithms such as [RandomForests](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), which also build committees of weak learners and average them for predictions. However, Random Forests rely on a different principle - that of the **bootstrap sample** or **bootstrapping** as well as randomness internal to the base model. \n",
    "\n",
    "A bootstrap sampling method as it pertains to machine learning works by training a large number of models each on a subset sample (which actually may be the same size as the original dataset) drawn **with replacement** from the original sample. Each subset sample is of size $M$, which could be up to $N$. These subset samples are called \"bootstrap samples\". The point is to introduce some variance which allows you to estimate the sample variance of a statistic under consideration. In machine learning, it allows you to reduce correlations between individual models trained on the bootstrap samples. We will analyze this property below. \n",
    "\n",
    "As an example, **Random Forests** are one algorithm in this category, and in addition to the randomness from the bootstrap they also have randomness in the features selected at each node of each tree in the comittee or \"forest\". The default `RandomForestClassifier` model in `scikit-learn` draws a bootstrap sample of the same size as the training dataset passed in the `.fit` function.\n",
    "\n",
    "Consider collecting a dataset $X$ of size $N$ data points $x_i$ in $\\mathbb{R}^k$ for a binary classification problem. Each of these data points also has a label $y_i \\in \\{0,1\\}$:\n",
    "\n",
    "$$ X = \\{ x_i,...,x_N \\} $$\n",
    "$$ Y = \\{ y_i, ..., y_N \\} $$\n",
    "\n",
    "Consider also that you have a **base model** of Decision Tree. We would like to train $B$ of these models (B is often very large, such as 1000s). Each model has the form:\n",
    "\n",
    "$$ T_i : \\mathbb{R}^k \\rightarrow \\{0,1\\} $$\n",
    "\n",
    "We train the models in the following manner:\n",
    "\n",
    "```\n",
    "Training:\n",
    "For each T_i, i=1,....,B:\n",
    "    (a) Draw a bootstrap sample of size M.\n",
    "    (b) Train a tree on the bootstrap sample. For each decision of the tree, calculate the best feature split based on a random subset of size p of the full number of features.\n",
    "    \n",
    "Output the forest, which is the set of all T_i, i=1,...,B\n",
    "\n",
    "```\n",
    "\n",
    "Typical values of $p$ might be $\\sqrt{k}$.\n",
    "\n",
    "Prediction is then done as follows. For a new data point $x$:\n",
    "\n",
    "$$ \\hat{y} =  \\sum_{i=1}\\frac{1}{B} T_i(b) $$\n",
    "\n",
    "Answer the following questions **in the cell below**:\n",
    "\n",
    "1. Consider the models $T_i$ trained above. In boosting, we also train a large set of models $T_i$. Because of the randomness in the training both in boosting and Random Forests, for any data point $x$ we can consider the outputs $T_i(x)$ each as a random variable. A set of random variables with the same possible values is identically distributed if their distributions are the same. Would you expect the $T_i$ in random forests to be identically distributed? What about for the $T_i$ in boosting? Explain why or why not for both. \n",
    "\n",
    "\n",
    "2. Would you expect the outputs of the individual $T_i$ to be indpendent after the algorithm above is performed? Why or why not?\n",
    "\n",
    "\n",
    "3. Suppose your $T_i$ were identically distributed. Then they all have the same mean, $\\mu$, and variance $\\sigma^2$. In Random Forests, your output is the average given by $\\hat{y}$ above, which is another random variable. What is the **expected value** of this random variable? \n",
    "\n",
    "\n",
    "4. Now note we did not assume that the variables are independent. Instead, assume all the $T_i$ have a small pairwise correlation coefficient $\\rho$. As a reminder, the pairwise correlation coefficient is given by:\n",
    "\n",
    "\n",
    "$$ \\text{corr}[X,Y] = \\frac{ \\text{cov}(X,Y) }{\\sigma_x \\sigma_y} $$\n",
    "\n",
    "And covariance is given by:\n",
    "\n",
    "$$ \\text{cov}[X,Y] = \\mathbb{E}[ (X - \\mu_x)(Y - \\mu_y) ] $$\n",
    "\n",
    "\n",
    "Prove that the variance of the output $\\hat{y}$ is given by:\n",
    "\n",
    "$$ \\text{var}[\\hat{y}] = \\rho \\sigma^2 + \\frac{1-\\rho}{B} \\sigma^2 $$\n",
    "\n",
    "This in turn shows that as you increase $B$, the variance of the output should decrease down to some minimum value. However, the first term does not decrease, and thus there is an irreducable amount of variance. This is expected since averaging over a large comittee of models has some irreducable variance if all the individual outputs are correlated, even if just slightly. \n",
    "\n",
    "\n",
    "**Here are some hints, in order:**\n",
    "\n",
    "Remember that for a random variable $X$:\n",
    "\n",
    "$$ \\text{var}[X] = \\mathbb{E}[ (X- \\mathbb{E}[X])^2 ] $$\n",
    "\n",
    "For a summation of i.i.d. random variables, \n",
    "\n",
    "$$ \\text{var}[ \\frac{1}{N} \\sum_{i=1}^N X_i ]= \\frac{ \\sigma_x }{N}$$\n",
    "\n",
    "However, the $T_i$ are not $i.i.d$. Instead, you need to expand the square in the first equation to yield a double summation. Then seperate the double summation into $B$ and $B^2-B$ terms, and apply the definition for $\\rho$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0716d2d5ed78f86a35dac57df7c74441",
     "grade": true,
     "grade_id": "cell-d868db621f653049",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ce6e302c74c903d500bffa423321f15",
     "grade": false,
     "grade_id": "cell-358d9cd5d83da332",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## The Task and Datasets\n",
    "\n",
    "Our task is to distinguish between images of \"faces\" and images of things that are not faces.\n",
    "\n",
    "The dataset(s) we will use are [Cifar10](http://vis-www.cs.umass.edu/fddb/) and the [Labeled Faces in the Wild(LFW)](http://vis-www.cs.umass.edu/lfw/) from UMass to create a \"face\"/\"non-face\" dataset.\n",
    "\n",
    "We only use Cifar10 for making \"non-face\" examples from the face dataset, since LFW does not have non-face pictures. To combine them together, we cropped and rescaled LFW images to be the same size as Cifar10 (32x32)\n",
    "\n",
    "We provide two functions below to download the datasets, perform some post-processing, and split the datasets into training/testing sets.\n",
    "\n",
    "Please do not modify these functions. The first time you run them, they may take a minute because they need to download the data. Expect ~400MB to be downloaded into the folder this notebook resides in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fd8e7dfe3a2c9f0e21dd0cd6d766439",
     "grade": false,
     "grade_id": "cell-2378de215e117bb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from cifar10_web import cifar10 \n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "from skimage.data import lfw_subset\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import integral_image\n",
    "from skimage.feature import haar_like_feature\n",
    "from skimage.feature import haar_like_feature_coord\n",
    "from skimage.feature import draw_haar_like_feature\n",
    "from skimage import feature\n",
    "import skimage\n",
    "\n",
    "print(skimage.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9ce1f4dc6cdc9cb7a6cf15da08723e2",
     "grade": false,
     "grade_id": "cell-dc9b9f49b6a82c10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_cifar():\n",
    "    '''\n",
    "    get_cifar\n",
    "    \n",
    "    Returns cifar10 dataset in greyscale\n",
    "    \n",
    "    train_images : np.ndarray of size (NumTrain, 32, 32)\n",
    "    train_labels : np.ndarray of size (NumTrain, )\n",
    "    \n",
    "    test_images : np.ndarray of size (NumTest, 32, 32)\n",
    "    test_labels : np.ndarray of size (NumTest, )\n",
    "    '''\n",
    "    train_images, train_labels, test_images, test_labels = cifar10(path=\"./\")\n",
    "    labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n",
    "    labels_map = { idx: label for idx,label in enumerate(labels)}\n",
    "\n",
    "    # Cifar10 labels are 1-hot encoded. Convert these to numeric labels.\n",
    "    _, train_labels = np.where(train_labels > 0)\n",
    "    _, test_labels = np.where(test_labels > 0)\n",
    "    \n",
    "    # Convert images to greyscale\n",
    "    train_images = train_images.reshape((-1,3,32,32)).transpose((0,2,3,1))\n",
    "    train_images = rgb2gray(train_images)\n",
    "    test_images = test_images.reshape((-1,3,32,32)).transpose((0,2,3,1))\n",
    "    test_images = rgb2gray(test_images)\n",
    "    \n",
    "    return train_images, test_images, train_labels, test_labels, labels_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bf1c80dcee8c06e13f228a08f627c0d",
     "grade": false,
     "grade_id": "cell-f7cc575857b2ad31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_faces_dataset(use_full_lfw=True, num_img=1000):\n",
    "    '''\n",
    "    get_faces_dataset\n",
    "    Returns a subset of the LFW faces dataset in greyscale\n",
    "    \n",
    "    Dataset consists of 100 faces and 200 non-face images \n",
    "    Dataset is split into 150 train, 50 validation, and 100 test images\n",
    "    \n",
    "    Returns: \n",
    "    \n",
    "    datset as dictionary (see below)\n",
    "    \n",
    "    '''\n",
    "    print(\"Building dataset. This may take a moment. Here is a random face from the LFW datset:\")\n",
    "    lfw_people = fetch_lfw_people(resize=0.25, slice_=(slice(68, 196), slice(68, 196)))\n",
    "    idx = random.randint(0,13000)\n",
    "    plt.imshow(lfw_people.images[idx,:,:], cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    \n",
    "    # Normalize to within the proper range.\n",
    "    lfw_people.images = lfw_people.images / 255.0\n",
    "    \n",
    "    num_negatives = num_img\n",
    "    if(not use_full_lfw):\n",
    "        faces_x = lfw_subset()\n",
    "        num_img = 100\n",
    "        num_negatives = 100\n",
    "        if(num_negatives > 100):\n",
    "            extra_negatives = np.zeros((num_negatives-100, 25, 25))\n",
    "            faces_x = np.vstack([faces_x, extra_negatives])\n",
    "    else:\n",
    "        print(\"copying over original LFW images.\")\n",
    "        faces_x = np.zeros((num_img+num_negatives, 32, 32))\n",
    "        for i in range(num_img):\n",
    "            faces_x[i, :, :] = lfw_people.images[i, :,:]\n",
    "    \n",
    "    # The current negatives are too easy in the subset. Replace with \n",
    "    # random cifar images\n",
    "    faces_y = np.concatenate([np.ones(num_img),np.zeros(num_negatives)])\n",
    "    trainCX, testCX, trainCY, testCY, cifar_label_map = get_cifar()\n",
    "    \n",
    "    faces_negs = (faces_y == 0.0)\n",
    "    print(\"copying over negative cifar10 examples\")\n",
    "    for i in range(num_negatives):\n",
    "        cifarImg = trainCX[i]\n",
    "        faces_x[num_img+i,:,:] = cifarImg\n",
    "        \n",
    "    face_mean = np.mean(faces_x[:num_img])\n",
    "    non_face_mean = np.mean(faces_x[num_img:])\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(faces_x, faces_y, \n",
    "                                                        train_size=0.75,\n",
    "                                                        random_state=0,\n",
    "                                                        stratify=faces_y)\n",
    "    \n",
    "    X_full_train = X_train\n",
    "    y_full_train = y_train\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n",
    "                                                          train_size=0.80,\n",
    "                                                          random_state=0, \n",
    "                                                          stratify=y_train)\n",
    "    \n",
    "    label_map = { 0: \"non-face\", 1: \"face\"}\n",
    "    \n",
    "    dataset = {\n",
    "        \"train\": {\n",
    "            \"images\": X_train,\n",
    "            \"labels\": y_train\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"images\": X_test, \n",
    "            \"labels\": y_test\n",
    "        },\n",
    "        \"valid\": {\n",
    "            \"images\": X_valid,\n",
    "            \"labels\": y_valid\n",
    "        },\n",
    "        # FULL TRAIN also conatins the validation data\n",
    "        # For use after parameter selection, right before evaluating test-set performance.\n",
    "        \"full_train\":{ \n",
    "            \"images\": X_full_train,\n",
    "            \"labels\": y_full_train\n",
    "        },\n",
    "        \"label_map\": label_map\n",
    "    }\n",
    "    \n",
    "                       \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff592b5314cc6aa5c77dbf7da5cd8be3",
     "grade": false,
     "grade_id": "cell-59ec04194f367fa1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Dataset Exploration\n",
    "\n",
    "The `get_faces_dataset` function we created above uses a subset of the LFW faces dataset and combines it with the Cifar10 dataset. The purpose of this is to create a datset with \"face\" and \"not face\" images. Otherwise the LFW dataset contains only faces. \n",
    "\n",
    "Here we provide some methods for plotting the images and how show you how to use them to visualize 4 randomly selected training images and the labels for those images the faces/Cifar10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daebc724932132a2553eb9523c73b0b9",
     "grade": false,
     "grade_id": "cell-dc4bcac021c30160",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = get_faces_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18ee50bce64df67eff944ab6900c5e01",
     "grade": false,
     "grade_id": "cell-23cdb6ed5d85aa3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Verify label distribution\n",
    "fig, axes = plt.subplots(1,3, figsize=(8,4))\n",
    "fig.tight_layout()\n",
    "ax = axes.ravel()\n",
    "ax[0].hist(dataset[\"train\"][\"labels\"])\n",
    "ax[0].set_title(\"Training Label Distribution\")\n",
    "ax[1].hist(dataset[\"valid\"][\"labels\"])\n",
    "ax[1].set_title(\"Validation Label Distribution\")\n",
    "ax[2].hist(dataset[\"test\"][\"labels\"])\n",
    "ax[2].set_title(\"Test Label Distribution\")\n",
    "plt.show()\n",
    "\n",
    "print(dataset[\"label_map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77a3720b8ebcdc1b929b24a6326d00e7",
     "grade": false,
     "grade_id": "cell-a88aa460071c9a89",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def show_img(img, label_str, ax):\n",
    "    '''\n",
    "    Args: \n",
    "        img - (m,m) np.ndarray\n",
    "               m is the side length of a square image\n",
    "        label - (str) the label for that image\n",
    "        ax - the axes to use for plotting with py plot\n",
    "    '''\n",
    "    side_length = int(math.sqrt(img.size))\n",
    "    ax.set_title(label_str)\n",
    "    ax.imshow(img*255.0, cmap = plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b590b5116d3c400cad4d293462f1ad7c",
     "grade": false,
     "grade_id": "cell-922f5a75044e2784",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# select 4 random faces images and print their labels.\n",
    "# you can re-run this cell multipe times to see different examples.\n",
    "fig, axes = plt.subplots(4,2, figsize=(8,8))\n",
    "fig.tight_layout()\n",
    "ax = axes.ravel()\n",
    "img_ids = np.random.randint(0, dataset[\"train\"][\"images\"].shape[0]-1, 8)\n",
    "for idx, i in enumerate(img_ids):\n",
    "    show_img(dataset[\"train\"][\"images\"][i], \n",
    "             dataset[\"label_map\"][dataset[\"train\"][\"labels\"][i]], \n",
    "             ax[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75a32980fb3b4a1866c332bb127dfe8c",
     "grade": false,
     "grade_id": "cell-4222b2730fd08dff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Selecting Features\n",
    "\n",
    "As we discussed in class / on Piazza, passing images as $W$ x $H$ (\"width\" by \"height\", here we are excluding color for simplicity in this assignment) arrays of floating point numbers to our algorithm is to use our pixels as features. In other words, we are using the \"pixel space\" representation of our image. This is a rather poor space to understand images semantically. To distinguish between digits in MNIST using decision trees, for example, would require a large tree or many weak classifiers when using Boosting. \n",
    "\n",
    "For this assignment, we will focus on using other kinds of features. Historically in computer vision, many different types of features have been popular for different tasks - HOG, SIFT, SURF, general edge features, etc. In more recent literature, deep convolutional neural networks (CNNs) have become popular tools for extracting features from images that are highly correlated with the images' **semantic information**, such as the presence or abscence of an object. In classification tasks, features such as these could allow us to more efficiently classify or detect objects in images. \n",
    "\n",
    "While deep learning certainly gets a lot of press, we will use a simple set of features called [\"Haar-like features\"](https://en.wikipedia.org/wiki/Haar-like_feature). These were popularized by the [Viola-Jones object detection algorithm](https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework) which demonstrated a \"real-time\" face detection algorithm in 2001. For this feat, the paper received several awards. The algorithm is still historically important, and it is interesting to compare and contrast Haar-like features from the features built by CNN algorithms (for more on that come to office hours).\n",
    "\n",
    "Below will implement a function to extract Haar-like features and explain a little more about what they are and how to calculate them.\n",
    "\n",
    "**Note**: \"real-time\" for Viola and Jones meant 2 frames-per-second (FPS) in 2001, but this might actually run in real time (60+ FPS) on hardware like a phone today.\n",
    "\n",
    "Ref: [Viola-Jones original paper](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)\n",
    "\n",
    "You will use the below functions in your code, but you do not need to modify them. Look them over to get an idea of what they will be used for (after you read the below explanation of \"Haar-like Features\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b15b68cbe7f883e2ae07fbb1a3ff9018",
     "grade": false,
     "grade_id": "cell-3f8474c8889121b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_integral_images(image_set):\n",
    "    '''\n",
    "    image_set : np.ndarray (N,M,M) set of images (as in the training or test images)\n",
    "    \n",
    "    returns the \"integral images\" which are used to calculate the haar features.\n",
    "    '''\n",
    "    int_image = np.zeros_like(image_set)\n",
    "    for i in range(image_set.shape[0]):\n",
    "        int_image[i,: , :] = integral_image(image_set[i])\n",
    "    return int_image\n",
    "\n",
    "def haar_features_from_image(img_integral, return_coords = False):\n",
    "    '''\n",
    "    Computes haar features for a single integral image\n",
    "    \n",
    "    Args:\n",
    "        img_integral: integral image for a single np.ndarray (M,M)\n",
    "        return_coords: whether or not to retrun box coordinates for each image.\n",
    "    \n",
    "    '''\n",
    "    width = img_integral.shape[0]\n",
    "    height = img_integral.shape[1]\n",
    "    feature_types = ['type-3-x', 'type-2-x', 'type-2-y']\n",
    "    features = haar_like_feature(img_integral, 0, 0, width, height, feature_type = feature_types)\n",
    "    if(return_coords):\n",
    "        feature_coord, feature_type = haar_like_feature_coord(width,height,\n",
    "                            feature_type=feature_types)\n",
    "        return features, feature_coord, feature_type\n",
    "    else:\n",
    "        return features\n",
    "    \n",
    "\n",
    "def filter_coord_by_area(coords, feature_types, min_area):\n",
    "    '''\n",
    "    Filters features by area\n",
    "    '''\n",
    "    keep = []\n",
    "    keep_t = []\n",
    "    for coord, typ in zip(coords, feature_types):\n",
    "        width = coord[-1][1][0] - coord[0][0][0]\n",
    "        height = coord[-1][1][1] - coord[0][0][1]\n",
    "        area = width*height\n",
    "        if(area > min_area):\n",
    "            keep.append(coord)\n",
    "            keep_t.append(typ)\n",
    "    return np.array(keep), np.array(keep_t)\n",
    "\n",
    "\n",
    "def get_haar_templates(feature_types=None):\n",
    "    '''\n",
    "    Returns haar templates for this task\n",
    "    '''\n",
    "    feature_coords, feature_types = haar_like_feature_coord(width=32, height=32,\n",
    "                            feature_type=feature_types)\n",
    "    return filter_coord_by_area(feature_coords, feature_types, 200)\n",
    "\n",
    "    \n",
    "def batch_haar_features(img_integrals, \n",
    "                        feature_types = None,\n",
    "                        feature_coords = None):\n",
    "    '''\n",
    "    Computes haar features given an integral image set\n",
    "    \n",
    "    This could be better vectorized, but the scikit-image functions \n",
    "    don't allow it.\n",
    "    \n",
    "    Args:\n",
    "        img_integral: integral image for a single np.ndarray (M,M)\n",
    "        feature_types/feature_coords: allows you to specify exactly which haar features to compute\n",
    "    \n",
    "    '''\n",
    "    width = img_integrals.shape[1]\n",
    "    height = img_integrals.shape[2]\n",
    "    \n",
    "    # calculate these first to get the right shape.\n",
    "    if(feature_coords is None):\n",
    "         feature_coords, feature_types = haar_like_feature_coord(width=32, height=32,\n",
    "                            feature_type=feature_types)\n",
    "    print(\"Total Features: {}\".format(len(feature_coords)))\n",
    "    def haar(idx):\n",
    "        return haar_like_feature(img_integrals[idx], 0, 0, width, height, \n",
    "                                             feature_type = feature_types,\n",
    "                                            feature_coord = feature_coords)\n",
    "    features = Parallel(n_jobs=-1,\n",
    "                   prefer=\"threads\", verbose=5)(map(delayed(haar), range(img_integrals.shape[0])))\n",
    "    features = np.array(features)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "233b50498ec3b5ad8921216f4eb0efbe",
     "grade": false,
     "grade_id": "cell-296e437a777c94b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_haar(images, int_imgs, labels, label_map, img_ids, coords=None):\n",
    "    '''\n",
    "    \n",
    "    Plots a 4x4 grid of images where each row \n",
    "    is a different image and image within the row displays a specific\n",
    "    Haar feature from the feature set. \n",
    "    \n",
    "    '''\n",
    "    if(coords is None):\n",
    "        feature_types = ['type-3-x', 'type-2-x', 'type-2-y']\n",
    "        coords, _ = haar_like_feature_coord(32, 32,\n",
    "                            feature_type=feature_types)     \n",
    "    \n",
    "    fig, axes = plt.subplots(len(img_ids), 4, figsize=(8,8))\n",
    "    fig.tight_layout()\n",
    "    ax = axes.ravel()\n",
    "    \n",
    "    for idx, i in enumerate(img_ids):\n",
    "        img = images[i]\n",
    "        int_img = int_imgs[i]\n",
    "\n",
    "        show_img(img, label_map[labels[i]], ax[idx*4])\n",
    "\n",
    "        # Select 4 random feature indices\n",
    "        ft_idx = np.random.randint(0, coords.shape[0]-1, 4)\n",
    "        for j in range(4):\n",
    "            img_haar = draw_haar_like_feature(img,0,0,img.shape[0],img.shape[1],\n",
    "                                             [coords[ft_idx[j]]])\n",
    "            ax[idx*4+j].imshow(img_haar)\n",
    "            ax[idx*4+j].set_title(\"{}\".format(ft_idx[j]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fc3390266059ef8ac752a347e6de6df",
     "grade": false,
     "grade_id": "cell-11dd5d5f5a32463d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### \"Haar-like\" Features\n",
    "\n",
    "Haar-like features are named after the [Haar-basis](https://en.wikipedia.org/wiki/Haar_wavelet), which is a set of functions with varying scales that form an orthogonal basis for 1-D or 2-D functions or signals. Don't worry if you don't understand too much about what exactly this means. Haar-like features are conceptually simple. Consider the following:\n",
    "\n",
    "![Figure1](haar1.png)\n",
    "\n",
    "Each of the above four rectangles (A,B,C,D), which consist of white and grey sub-rectangles, is a single **feature template**. Each feature template is an axis-aligned rectangle. The important part about this template is the relative position of the white area with respect to the grey area. These feature templates are functions. They take values +1 on pixels that overlap with the white area and $-1$ on features that overlap with the grey area. Let's call these four sub-rectangles the \"mother-templates\" and give them names: \n",
    "\n",
    "$$ A=\\psi_1(x,y), B=\\psi_2(x,y), C=\\psi_3(x,y), D=\\psi_4(x,y) $$\n",
    "\n",
    "Now, suppose we could move these mother-templates to different points in the above image. Then we can make a different template for each **location** in the image. Consider a templates \"location\" as is the (x,y) coordinates of its upper left hand corner. We'll denote the location of the template by a coordinate $(x,y)$ where $(0,0$ is the upper left-hand corner of the image. Finally, we can stretch the template to have different widths and heights, so the templates have 4 sources of variation: $(x,y, w,h)$:\n",
    "\n",
    "So here is how we describe all our templates:\n",
    "\n",
    "$$ \\Psi = \\{ \\psi_{i,(x,y,w,h)} | i \\in \\{1,2,3,4\\}, (x,y,h,w) \\in \\{0,...,W-1 = H-1\\}^4 \\} $$\n",
    "\n",
    "\n",
    "**To calculate the feature-value** for each of these templates, we overlay the template on the image at the correct position and scale determined by the features $(x,y,w,h)$ coordinates, then we **sum the values of all the image pixels covered by the white (+1) region of the template** and **subtract all the values of the pixels covered by the grey part of the template**. The result is a single number.\n",
    "\n",
    "Thus, after evaluating all the features for a single image, we will have a vector of numbers. This is now the feature vector for the image.\n",
    "\n",
    "After we enumerate all these templates, how many total feature-templates are in $\\Psi$? \n",
    "\n",
    "We won't write out a formula, but for a $32 \\times 32$ image like in Cifar10, there are 509,270 possible features that are calculated from the above templates. (If that seems like a lot, try to calculate roughly how many there should be based on the above description). \n",
    "\n",
    "Because of this, even on modern hardware, it can take a second to compute all those. Furthermore, it seems intuitively unreasonable to have 500,000 features for a single image. However, we will find out that a handful of these features can be highly correlated with objects in greyscale images, and if we can find those good features, that have many useful properties we will explore below.\n",
    "\n",
    "For each image in Cifar10, based on the above, we will get a vector of length $509,270$.\n",
    "\n",
    "Clearly, **most of these features** will be pretty useless when classifying objects. However, **some of them will be highly correlated to specific patterns**:\n",
    "\n",
    "![Figure2](haar2.png)\n",
    "\n",
    "Of course, in computer science (especially in the dark ages in 2001), it is important to havea way to efficiently compute these features. To do so, the scikit-learn backend uses an [integral image](https://en.wikipedia.org/wiki/Summed-area_table), which can calculate any of the Haar-like features in constant time (4 lookup in the integral image). However, with the shear number of possible features, it is computationally expensive to compute all of them. \n",
    "\n",
    "In this assignment, we aren't too focused on how to compute these features. Instead, we just need to know that there are **a lot** of them, but potentially we could select a few using AdaBoost and then train a new boosted classifier using a smaller subset of the Haar-features, which would be very fast to compute.\n",
    "\n",
    "Ref:\n",
    "\n",
    "- [Viola-Jones Paper](https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/viola-cvpr-01.pdf)\n",
    "- [A video visualization of this exact algorithm in OpenCV](https://vimeo.com/12774628). Here we see the sliding-window detection implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6a4bdb0acd6b076d54877eb6975c074e",
     "grade": false,
     "grade_id": "cell-78eeca291d91c8e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualizing Example Haar-like Features\n",
    "\n",
    "We have written some helper functions above which take advantage of utilities provided by `scikit-image` to calculate the features.\n",
    "\n",
    "In the plots below, we see a green and red rectangle (corresponding to white and grey regions above). Red is the \"negative\" region. Above each plot is the index of the feature.\n",
    "\n",
    "For each image, we show 4 random possible features out of the 200k+ features we could calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "213035ce012bdacc0bca75d3d8f7eee4",
     "grade": false,
     "grade_id": "cell-8608ee8bcc5591c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# select 4 random face dataset images and visualize them with some\n",
    "# haar features\n",
    "print(\"Calculating some Haar features for faces dataset...\")\n",
    "X_train_faces_integral = compute_integral_images(dataset[\"train\"][\"images\"])\n",
    "img_ids = np.random.randint(0, X_train_faces_integral.shape[0]-1, 4)\n",
    "plot_haar(dataset[\"train\"][\"images\"], X_train_faces_integral, \n",
    "          dataset[\"train\"][\"labels\"], dataset[\"label_map\"], \n",
    "          img_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16c0d4a7e447f7767c6494abc8d3d8dc",
     "grade": false,
     "grade_id": "cell-816d2a07de94a039",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Haar-like Feature Questions (2pts)\n",
    "\n",
    "Please answer the following question to test your understanding of these features. \n",
    "\n",
    "Suppose the image is of size $ 8 \\times 8$. You have one Haar \"mother template\" feature which is non-zero on a grid of $1 \\times 2$ pixels. The left pixel has the $+1$ region and the right is the $-1$ region. All scaled and repositioned versions of this template consist of all possible rectangular sub-regions of the full $8 \\times 8$ grid where the left half of the rectangle is the $+1$ region and the right half is the $-1$ region. How many possible features can be generated from this template? \n",
    "\n",
    "Note that the smallest possible template here is the mother template, and \"all possible rectangular sub-regions\" means that you don't count templates that extend past the image. So the mother template positioned with the +1 pixel on the right edge of the image does not count. \n",
    "\n",
    "You must explain your work. \n",
    "\n",
    "Hints: \n",
    "- You can't \"reflect\" the $1 \\times 2$ template so that the $-1$ appears on the left. That is a different mother-template, so need need to count those.\n",
    "- For the $1 \\times 2$ mother template, you can position it at all possible $1 \\times 2$ rectangular sub-regions in the image. For each row of the image, there are $7$ possible $1 \\times 2$ sub-regions. Thus there are $8 \\times 7 = 56$ posible $1 \\times 2$ features at this scale.  \n",
    "- The largest possible scale for this mother template is $8 \\times 8$. There is exactly one possible position for this template, since we don't count when it extends beyond the image.\n",
    "\n",
    "We just counted the number of features for scales 1 and 8. Now you just have to do scales (1,N),(2,N),...,(8,N) where $N$ ranges from $2$ to $8$, except for scales (1,2) and (8,8). Rather than counting (that would take a while), derive a formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ebdfbbb7a1e70c10257c84f913afd03a",
     "grade": true,
     "grade_id": "cell-6f88d1e5fcf6e9d3",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0154d500d7be10e5fd9939640b82ca3",
     "grade": false,
     "grade_id": "cell-1749dd80f5ebf252",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### AdaBoost for Face Detection\n",
    "\n",
    "We will now train [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) with depth-1 [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) as the \"weak  base classifier\" to classify $32 \\times 32$ pixel images as either \"face\" or \"no face\".\n",
    "\n",
    "In computer vision, typically a \"detection\" algorithm includes localizing a detected object within an image. In the original Viola-Jones paper, they first train a classifier using the method that we walk you through below. Then, they use this classifier in a sliding-window manner on larger images to detect faces. We will do only the first part in this assignment, and the second part is extra credit (but is the most satisfying result to see).\n",
    "\n",
    "In addition, the only difference between what they do in the paper and what is done here is that multiple classifiers are created in a tiered manner. So many AdaBoostClassifiers would be trained and applied in stages where earlier stages have fewer features. They do this because they find it helps improve accuracy without sacrificing speed since the algorithm can \"bail out\" at early stages when the detection probability is low. However, we will not implement this staged feature. \n",
    "\n",
    "The steps we will do this are as follows:\n",
    "\n",
    "1. First we will write a function `build_boosted_dt` to build a basic boosted decision tree using `AdaBoostClassifier` with a base class of `DecisionTreeClassifier`\n",
    "\n",
    "- Because we will use this function for building deicion tree classifiers for images with raw pixel features and Haar features, it's important that within the DecisionTreeClassifier base parameters, you set **\"max_features\"**\n",
    "- You should also set **random_state=0** in both the DeciionTreeClassifier base class as well as the AdaBoostClassifier object.\n",
    "- Your `build_boosted_dt` function should accept parameters `max_ensemble_size`, `max_depth`\n",
    "\n",
    "2. Then we will apply this algorithm on the naive \"raw pixels\" form of our dataset. This will give us a good baseline to compare against the same algorithm using the Haar subset.\n",
    "3. We will analyze the performance characterstics as a function of maximum ensemble size of this classifier.\n",
    "4. We will then extract all possible Haar-like features from the dataset images and run a AdaBoost algorithm with as a way to perform feature selection for a subset of the 200,000+ Haar features.\n",
    "5. Finally, we will train a final boosted depth-1 decision tree to on our Haar subset. \n",
    "\n",
    "The output should be a highly precise, interpretable, and very fast face-detection algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84404d43f76751bd1dc5b4d6b9d00713",
     "grade": false,
     "grade_id": "cell-ce57d2ed53b3f356",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a7220895edcc84c623153bb3256ff9b",
     "grade": false,
     "grade_id": "cell-4874435f96407156",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Build the Boosted Classifier Factory Function (2 pts)\n",
    "\n",
    "Fill out the function below to build the boosted classifier using Scikit-learn's [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9aeb6b9bf8343965737f3ad774cf493",
     "grade": false,
     "grade_id": "cell-c00c0a9b55e54936",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_boosted_dt(features, labels, max_ensemble_size=10, max_depth=1, max_features=None):\n",
    "    '''\n",
    "    build_boosted_dt\n",
    "    \n",
    "    args: \n",
    "        features - np.ndarray of shape (NumExamples, NumFeatures)\n",
    "        labels - np.ndarray of shape (NumExamples,)\n",
    "        max_ensemble_size - the maximum number of estimators that AdaBoost uses\n",
    "        max_depth - max depth of the base DecitionTreeClassifier\n",
    "    returns: \n",
    "    \n",
    "        a scikit-learn AdaBoostClassifier, with a base classifier of DecisionTreeClassifier\n",
    "    \n",
    "        the AdaBoostClassifier should be fitted to the features and labels.\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b876aab3e1e43f5e420178325601d455",
     "grade": true,
     "grade_id": "cell-e2bdfc374c3dcef4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not delete this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d86d3153e13223867c2da3cc647c96d",
     "grade": false,
     "grade_id": "cell-4ca6ca5fe17a81cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Evaluate the Boosted Classifier using Pixel Features on the Faces Dataset (6 pts)\n",
    "\n",
    "We are first going to try the \"naive\" approach, which is similar to what we did with MNIST - classifying based on shallow decision trees that draw thresholds as functions of the value of a single pixel. \n",
    "\n",
    "#### Fill in the function below to build the classifier using different numbers for the max ensemble size.\n",
    "\n",
    "- In the first cell, you should fill in only the function `bdt_evaluation`, which automates the building and assessing recall, precision, accuracy, and runtime performance on the validation data.\n",
    "- Follow the function spec\n",
    "- You should fix the max_depth of the base tree to be 1.\n",
    "- Note you shouldn't use the global variables in `dataset` inside this function.\n",
    "\n",
    "#### Second Task (evaluation): \n",
    "In the second cell, you can write the code to actually call `bdt_evaluation` and plot your results using the raw image as features into the classifier.\n",
    "\n",
    "The specific things you need are:\n",
    "- A plot of accuracy vs. max number of classifiers in the ensemble\n",
    "- A plot of precision and recall vs. max number of classifiers (both precision and recall in the same plot)\n",
    "- A plot of runtime (for the fit procedre) vs. max number of classifiers in the ensemble\n",
    "- A plot of runtime (for the inference on the validation set) vs. max number of classifiers in the ensemble. Report this procedure in \"sec / image\"\n",
    "- Print out the maximum accuracy, precision, and recall, as well as the values of `max_ensemble` that achieve those values on the validation set. \n",
    "\n",
    "- Now since we are performing face recognition, select a value for `max_ensemble` that maximizes recall for a resonable precision tradeoff. Re-build the classifier using `build_boosted_dt` and report precision, recall, and accuracy on the **test set**.\n",
    "\n",
    "- Note that the classifier wants a linear set of features, but the X_train_faces is of shape (N, M, M ) Thus, you need to reshape it to (N, M*M ) before you bass to `bdt_evaluation`.\n",
    "\n",
    "We set `max_ensemble_range` to be the values you should use to pass into `bdt_evaluation`.\n",
    "\n",
    "Notes:\n",
    "- Note you may reuse the `bdt_evaluation` function, so you shouldn't do anything in there particular to one set of features or another.\n",
    "- You may use the [sckit-learn functions for metrics](https://scikit-learn.org/stable/modules/classes.html), which we've imported above already.\n",
    "- We import Parralel and delayed from [joblib]() if you know how to use parallel loops, you can use it within your bdt_evaluation function. Please use a concurrency level <= 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "268f72998cede3533887e3353084cc1a",
     "grade": false,
     "grade_id": "cell-9362920438437715",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def bdt_evaluation( X_train, y_train,\n",
    "                    X_valid, y_valid,\n",
    "                    max_ensemble_values = range(1,11)):\n",
    "    '''\n",
    "    bdt_evaluation\n",
    "    \n",
    "    loop over all values in max_ensemble_values\n",
    "    \n",
    "        - call build_boosted_dt on the train data\n",
    "        - evaluate acc, recall, precision on the validation data,\n",
    "        - save those values in arrays to return as described below\n",
    "    \n",
    "    Args:\n",
    "        X_train - np.ndarray of size (NumTrainExamples, NumFeatures) \n",
    "        y_train - np ndarray of size (NumTrainExamples, )\n",
    "        X_test - np .ndarray of size (NumTestExamples, Num Features)\n",
    "        y_test np.ndarray of size (NumTestExamples, )\n",
    "        max_ensemble_values\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of the form\n",
    "        {\n",
    "            \"accuracy\": np.ndarray containing the accuracy values, one for each value in \n",
    "                        the input argument \"max_ensemble_values\",\n",
    "            \"precision\": np.ndarray containing the precision values, one for each value in \n",
    "                        the input argument \"max_ensemble_values\",\n",
    "            \"recall\": np.ndarray containing the recall values, one for each value in \n",
    "                        the input argument \"max_ensemble_values\",\n",
    "            \"runtime_inference\": np.ndarray containing how long it took to perform \n",
    "                        validation set prediction for the value of \"max_ensemble_values\"\n",
    "                        given by the index.\n",
    "                        Don't include metric calculations in this number.\n",
    "                        You can use time.time() to get start and end times\n",
    "            \"runtime_train\": np.ndarray containing how long it took to perform training set\n",
    "                        fitting  for the value of \"max_ensemble_values\"\n",
    "                        given by the index.\n",
    "                        You can use time.time() to get start and end times\n",
    "        }\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0310fc3c2ade17b326f77751d0551cb8",
     "grade": true,
     "grade_id": "cell-d1003024ba19a562",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Do not delete this cell. Do not write anything in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7658ad9c8b36bdf85c65df1afa37a934",
     "grade": false,
     "grade_id": "cell-74c6d09b9a958f9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Your answer to the second part goes in the cell below.\n",
    "\n",
    "It should take ~30-40 lines of code for all plots and metrics.\n",
    "\n",
    "Our solution runs in 1.9 seconds\n",
    "\n",
    "You should use the following when calling `bdt_evaluate`:\n",
    "\n",
    "```\n",
    "max_ensemble_range = list(range(1,32,2))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bfa11f95f68253aeaff7fc27afb409d",
     "grade": true,
     "grade_id": "cell-eeff5d8a2a0d7ebf",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYSIS QUESTIONS (4 pts)\n",
    "\n",
    "Based on the graphs above, answer the following questions:\n",
    "\n",
    "1. What are the tradeoffs involved in terms of runtime/computational resources and the increased ensemble size?\n",
    "\n",
    "\n",
    "\n",
    "2. What does the `max_features` parameter in Scikit-Learn's DecisionTreeClassifier control? If we didn't set this parameter, how many features would be used if we passed in data with 100,000 features?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a30298e04f41dd02f197cff3a3c510f",
     "grade": true,
     "grade_id": "cell-df8b7864327931a6",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3d11857e155b98c317a4938d856fb13",
     "grade": false,
     "grade_id": "cell-59b12679e12ba068",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Haar Feature Selection and Use with AdaBoost (10 pts)\n",
    "\n",
    "Now we want to do the same thing as above, but this time for Haar features. However, there is a problem. If we were to simply take all the Haar features given by our `batch_haar_features` function, we would end of with about 100,000 features per images. This wouldn't nearly be a fair comparison to the $32 \\times 32$ pixel features available to classifier above. \n",
    "\n",
    "To reduce our features, we do the following. \n",
    "1. Train Adaboost out with a large ensemble size (100) and all the features (~100,000) per image.\n",
    "2. We will inspect which features AdaBoost \"favors\" by looking at the ensemble weights (the $\\alpha_k$ from class). \n",
    "3. We will then select a much smaller subset on par with the 1024 pixel features in the raw image. \n",
    "\n",
    "The hope is that these features will give us better performance than the pixel features, and in addition that they will be interpretable (we can look at the pattern of the feature, and it may correspond to certain features in faces), and also very fast.\n",
    "\n",
    "In addition, we could hope that we could apply these features onto a larger image where we can assess whether or not a face is in each 32 x 32 window of the image, and further we could generalize them to different scales rather easily for larger windows. There is no reason to belive the decision tree algorithm on pixel could be generalized in such a manner. \n",
    "\n",
    "The code below you need to write is the following\n",
    "\n",
    "1. Compute the integral images for the train and valid data sets using the `compute_integral_images` function.\n",
    "2. Compute the haar features using the `batch_haar_features` function. This may take up to a couple minutes on your computer.\n",
    "3. Train AdaBoost with a depth-1 decision tree and 100 max ensemble size using your `build_boosted_dt` function on the **training data**. This may take several minutes. \n",
    "4. Report the accuracy, precision, and recall for your classifier **on your validation set**. At this point, it should be exremely high.\n",
    "5. Inspect the feature \"importance weights\" of the classifier by calling the `.feature_importances_` method of your trained AdaBoostClassifier. This returns the set of feature weights, calculated by counting all the times a feature was used by one of the weak classifiers, weighted by the ensemble weight. The are normalized to add up to one. Plot a histogram that shows the distributions of these weights. Do you have many weights that are nonzero? Or do you have a \"sparse\" set of weights?\n",
    "6. Select the best set of 600 haar features using the `.feature_importances_` and `get_best_haar_features` function we provide for you.\n",
    "7. Rebuild the haar features using the `batch_haar_features` function **on the training set**. This time pass in the `feature_coord_best` and `feature_type_best` to the `batch_haar_features` function. This should build these functions very fast.\n",
    "8. At this point, we now have selected our subset. But we need to select ensemble size again. For this, we will use `bdt_evaluate` as we did above. Make the same set of plots:\n",
    "\n",
    "\n",
    "- A plot of accuracy vs. max number of classifiers in the ensemble\n",
    "- A plot of precision and recall vs. max number of classifiers (both precision and recall in the same plot)\n",
    "- A plot of runtime (for the fit procedre) vs. max number of classifiers in the ensemble\n",
    "- A plot of runtime (for the inference on the validation set) vs. max number of classifiers in the ensemble. Report this procedure in \"sec / image\"\n",
    "- Print out the maximum accuracy, precision, and recall, as well as the values of `max_ensemble` that achieve those values on the validation set. \n",
    "\n",
    "\n",
    "9. Rebuild the classifier with the appropriate features and max ensemble size on the **full training set (including validation)**\n",
    "10. Report precision, recall, and accuracy on the **test set**. \n",
    "11. Use the `plot_haar` function we wrote above to visualize the \"highest weight\" features. Be sure to pass these to the `coords` parameter for `plot_haar`.\n",
    "\n",
    "We split the cells below so that you can put the computationally heavy portions in seprate cells then iterate on the rest in the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c81fc2c391720713ef0c912118c38ba",
     "grade": false,
     "grade_id": "cell-851f215e60a861d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function. Feel free to use this at step 6 \n",
    "def get_best_haar_features(feature_weights, num_features, feature_types=None):\n",
    "    '''\n",
    "    get_best_haar_features\n",
    "    Args\n",
    "        feature_weights: the weights given by classifier.feature_importances_ \n",
    "        num_weights: (integer) select the top \"num_weights\" features\n",
    "        feature_types: the list of feature types originally generated (given below)\n",
    "        \n",
    "    Returns\n",
    "        feature_coords_best, feature_types_best\n",
    "        \n",
    "        The above two arrays should be passed to \"batch_haar_features\" in order to generate\n",
    "        the final features in step 7.\n",
    "    '''\n",
    "    feature_coords, feature_types = get_haar_templates(feature_types)\n",
    "    \n",
    "    # Sort the indices in decreasing weight\n",
    "    idx_sorted = np.argsort(feature_weights)[::-1]\n",
    "    feature_coords_best = feature_coords[idx_sorted[:num_features]]\n",
    "    feature_types_best = feature_types[idx_sorted[:num_features]]\n",
    "    \n",
    "    print(\"Feature weight: \", np.sum(feature_weights[idx_sorted[:num_features]])/np.sum(feature_weights))\n",
    "    \n",
    "    return feature_coords_best, feature_types_best\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f0248603847add76dee15cac6b149d3",
     "grade": false,
     "grade_id": "cell-8ca61ee23fa8fd58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This cell is for step 1+2\n",
    "This could take a couple minutes on a slower laptop CPU\n",
    "\n",
    "We give you the following parameters to pass to the function \"batch_haar_features\".\n",
    "This reduces the number of features used, making the procedure cheaper.\n",
    "```\n",
    "haar_types = ['type-3-x', 'type-2-x', 'type-2-y']\n",
    "feature_coords, feature_types = get_haar_templates(haar_types)\n",
    "```\n",
    "\n",
    "This step should take ~10 lines of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbea03bacdb41590dc16a0d7dec7af47",
     "grade": true,
     "grade_id": "cell-f3b94396cc1fb50a",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b1af8686ee9d221f6a43df4882ef7af",
     "grade": false,
     "grade_id": "cell-6c00b2f5b3d8d68c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The below cell is for step 3.\n",
    "It should take Should be ~1 line of code\n",
    "\n",
    "Use the following parameters:\n",
    "```\n",
    "max ensemble size should be 100\n",
    "max depth should be 1\n",
    "max_features=1000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2ea31baac0c77429f3dd2dde6c8f71c",
     "grade": true,
     "grade_id": "cell-ee52d38e3d56dbb5",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2310cd6ed427189b8a1af5886784c955",
     "grade": false,
     "grade_id": "cell-a552739cd4b4fe28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This cell is for step 4.\n",
    "It should take ~4 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37c90ae0f67591c80fc8ae064d50484b",
     "grade": true,
     "grade_id": "cell-5317c903428d48e1",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8726602aff3279f1fbf9bdb741bd20c8",
     "grade": false,
     "grade_id": "cell-765c18fa6b0af2234234",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the below cell for steps 5-6.\n",
    "It should take ~4 two lines of code.\n",
    "Use `num_features=1024` and be sure to pass in `haar_types` to `get_best_haar_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61ef2e87d7a7408ec00d337c847acf71",
     "grade": true,
     "grade_id": "cell-765c18fa6b0af228",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5103a41e2cdc887676053dcfb0d16b38",
     "grade": false,
     "grade_id": "cell-75873ce3ab00d43f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below cell is for steps 7-10\n",
    "It should take ~ 40-50 lines of code for all plots. You also need to rebuild all features in the beginnning with \n",
    "the new features subset you found in the above step.\n",
    "\n",
    "Ensure you set the following when conducting the evaluation with `bdt_evaluation`:\n",
    "```\n",
    "max_ensemble_range = list(range(1,32,2))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bccbe4158ef22662c4e33649f15b03a9",
     "grade": true,
     "grade_id": "cell-1bb97fe0b678a868",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63cbcfcabce7f7a26ec3f9b12c77f52b",
     "grade": false,
     "grade_id": "cell-aa361c73aff9a15723422",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The final cell here is for step 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94446f11c72e64dc9bf750daa4bea173",
     "grade": true,
     "grade_id": "cell-aa361c73aff9a157",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "744afa5ae38c1a16b5fbc1311b895d0f",
     "grade": false,
     "grade_id": "cell-54af9e20e6365e81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Final Analysis (6pts)\n",
    "\n",
    "#### What did we accomplish?\n",
    "\n",
    "So far we have done the following:\n",
    "\n",
    "- We trained the AdaBoostClassifier with a base DecisionTreeClassifier on the \"pixel features\" of the dataset, and selected the `max_ensemble_size` parameter basd on validation performance. We plotted graphs of the accuracy, precision, and recall of this ensemble classifier vs the max ensemble size. We also plotted the amount of time it took to fit and predict using these ensemble classifers of varying size. Then we selected a parameter, retrained the model, and evaluated the test set precision, recall, and accuracy.\n",
    "\n",
    "\n",
    "**QUESTION 1**\n",
    "\n",
    "Summarize your final **pixel-feature** based model here. What was the ensemble size you picked? What was the test set precision, recall, and accuracy? What were the runtime performances?\n",
    "\n",
    "\n",
    "- We trained the AdaBoostClassifier with a base DecisionTreeClassifier on the \"haar features\" of the dataset, selected a susbset of the features, rebuilt the classifier using those features, and selected the `max_ensemble_size` parameter basd on validation performance. We plotted graphs of the accuracy, precision, and recall of this ensemble classifier vs the max ensemble size. We also plotted the amount of time it took to fit and predict using these ensemble classifers of varying size. Then we selected a parameter, retrained the model, and evaluated the test set precision, recall, and accuracy.\n",
    "\n",
    "**QUESTION 2**\n",
    "\n",
    "Summarize your final **Haar-like feature** based model here. What was the ensemble size you picked? What was the test set precision, recall, and accuracy? What were the runtime performances?\n",
    "\n",
    "**QUESTION 3**\n",
    "Compare the above two models. You may find that accuracy/precision/recall were similar. This is somewhat a factor of the \"easiness\" of the task and data. You should also compare runtime performance, however. Consider that if we used this model in a sliding-window detection scheme, we would have to run it 1000s of times for every image, so a small difference in runtimes may add up. You should also compare interpretability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76468f98b441aae7d79090fa10eb0171",
     "grade": true,
     "grade_id": "cell-6d38b7f80d19d703",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbe5de478aeb5a3fdd32fb149c3e728f",
     "grade": false,
     "grade_id": "cell-2bea71cc96f062cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Extra Credit: Perform Face Detection on a Large Image (4pts)\n",
    "\n",
    "For the bonus round, find an image with many small faces facing the camera. \n",
    "\n",
    "Here's an example of such an image: [largest group selfie ever](https://www.cs.cmu.edu/~peiyunh/tiny/).\n",
    "\n",
    "Use the algorithm we trained in a sliding-window manner to try to detect faces. Output the image with boxes around the detections. You must include all code (including drawing the boxes, etc). You may not import/use OpenCV. \n",
    "\n",
    "Here's a result we were able to come up with rather quickly (~30 lines of code). \n",
    "\n",
    "As you can see, we are only detecting at one scale (32 x 32), so that places a large limitation on our performance. In fact, many faces in the second image are 32x32, so it performs rather well mid-crowd.\n",
    "\n",
    "The faces range from very tiny to hundreds of pixels large. We could extend this relatively easily by scaling our dataset and training the detector at multiple scales. This would involve training multiple detectors on images of different scales. You could even just synthetically augment existing data by scaling to different sizes.\n",
    "\n",
    "Finally, our current detector is rather slow. It took about (~1 min) per image on an Intel i5-9500. This is because it runs the full AdaBoostClassifier on each 32x32 batch with stride 8 (meaning after each batch, it slides up or down by 8 pixels to get to the next batch). The original algorithm used a \"cascade\" of classifiers where the first classifier used only 8 features to quickly reject non-face patches with high recall rate. See the original paper for more details. OpenCV has an efficient implementation.\n",
    "\n",
    "The below two images are detections at different strides / threshold levels:\n",
    "\n",
    "![FacePredictions1](crowd2_sample.jpg)\n",
    "\n",
    "![FacePredictions2](crowd2_dense.jpg)\n",
    "\n",
    "Hints:\n",
    "1. Control how finely you \"stride\" your window over the image for better detections.\n",
    "2. You shouldn't use all predictions where the classifier outputs \"1\". Use a threshold you can tune, and use the method \".predict_proba\" from your `AdaBoostClassifier` class. \n",
    "3. You will notice above that many predictions are overlapping. In almost all object detection systems, including the most popular CNN based methods, you need to implement [non-max-suppression](https://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/) combining your outputs, the classifier confidence, and some intersection thresholds to prune the outputs in a greedy manner such that the most confident \"suppress\" the less confident boxes with which it overlaps. We did not implement any NMS for this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aaa7f53d9f5eabcd23541a43d874271d",
     "grade": true,
     "grade_id": "cell-31aad33174dc9459",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "from skimage.draw import rectangle_perimeter\n",
    "\n",
    "def predict_img(img_name, bdt, feature_type, feature_coord, rescale=None, threshold=0.5,stride=16, crop=None):\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
